# üìä Projeto ETL - Ingest√£o e Tratamento de Dados com AWS Glue

Este projeto implementa uma solu√ß√£o completa de **ETL (Extract, Transform, Load)** usando **AWS Glue** como ferramenta visual para ingest√£o e tratamento de dados, com **Aurora Serverless PostgreSQL** como banco de dados de destino.

## üéØ Objetivo

Criar um pipeline de dados que:
- **Ingere** dados de m√∫ltiplas fontes (CSV, TSV)
- **Transforma** e limpa os dados usando AWS Glue
- **Carrega** os dados tratados em um banco PostgreSQL
- **Consolida** informa√ß√µes de diferentes fontes em uma tabela final

## üèóÔ∏è Arquitetura da Solu√ß√£o

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dados Locais  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Amazon S3  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   AWS Glue      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Aurora Serverless‚îÇ
‚îÇ   (CSV/TSV)     ‚îÇ    ‚îÇ  (Raw Data)  ‚îÇ    ‚îÇ (ETL Visual)    ‚îÇ    ‚îÇ   PostgreSQL     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ                      ‚îÇ
                              ‚ñº                      ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ Glue Catalog ‚îÇ    ‚îÇ Tabela Final    ‚îÇ
                       ‚îÇ (Metadados)  ‚îÇ    ‚îÇ Consolidada     ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Estrutura dos Dados

### Fontes de Dados (Pasta `Dados/`):

1. **üìà Reclama√ß√µes** (`Dados/Reclamacoes/`)
   - Dados trimestrais de reclama√ß√µes banc√°rias (2021-2022)
   - Formato: CSV com separador `;`
   - Cont√©m: CNPJ, institui√ß√£o, quantidade de reclama√ß√µes, √≠ndices

2. **üè¶ Bancos** (`Dados/Bancos/`)
   - Informa√ß√µes de enquadramento das institui√ß√µes financeiras
   - Formato: TSV (Tab-separated values)
   - Cont√©m: Segmento, CNPJ, nome da institui√ß√£o

3. **üë• Empregados** (`Dados/Empregados/`)
   - Avalia√ß√µes de funcion√°rios do Glassdoor
   - Formato: CSV com separador `|`
   - Cont√©m: Avalia√ß√µes, cultura, sal√°rios, benef√≠cios

### Tabelas de Destino no Aurora:

- **`reclamacoes`** - Dados consolidados de reclama√ß√µes
- **`bancos_enquadramento`** - Informa√ß√µes dos bancos por segmento
- **`empregados_glassdoor`** - Avalia√ß√µes dos funcion√°rios
- **`dados_consolidados`** - **Tabela final** com dados unidos e tratados

## üõ†Ô∏è Componentes da Solu√ß√£o

### 1. **Amazon S3** - Armazenamento de Dados
- **Bucket de dados**: Armazena arquivos CSV/TSV originais
- **Bucket de scripts**: Cont√©m scripts Python do Glue
- **Bucket tempor√°rio**: Arquivos tempor√°rios do processamento

### 2. **AWS Glue** - Ferramenta Visual de ETL
- **Glue Studio**: Interface visual para criar jobs de ETL
- **Glue Catalog**: Cat√°logo de metadados das tabelas
- **Glue Crawler**: Descobre automaticamente esquemas dos dados
- **Glue Job**: Executa o processamento ETL

### 3. **Aurora Serverless v2 PostgreSQL** - Banco de Dados
- **Serverless v2**: Paga apenas pelo que usa, auto-scaling cont√≠nuo
- **Capacidade**: 0.5-2 ACU (Aurora Capacity Units)
- **Escalabilidade**: Escala automaticamente conforme demanda
- **Economia**: Reduz para 0.5 ACU quando inativo

### 4. **Networking e Seguran√ßa**
- **VPC**: Rede privada isolada
- **Subnets**: P√∫blicas (NAT) e privadas (Aurora/Glue)
- **Security Groups**: Controle de acesso entre componentes
- **IAM Roles**: Permiss√µes granulares para cada servi√ßo

## üöÄ Como Executar

### Pr√©-requisitos
- AWS CLI configurado (`aws configure`)
- Terraform instalado (>= 1.0)
- PostgreSQL client (psql) para verifica√ß√£o

### Execu√ß√£o Completa

```bash
# 1. Inicializar Terraform
terraform init

# 2. Aplicar toda a infraestrutura (15-20 min)
terraform apply

# 3. Criar tabelas no Aurora
terraform output -raw create_tables_command | bash

# 4. Verificar dados carregados
terraform output -raw data_verification_command
```

### O que Acontece Automaticamente:

1. ‚úÖ **Infraestrutura AWS** criada (VPC, S3, Aurora, Glue, IAM)
2. ‚úÖ **Upload de dados** da pasta `Dados/` para S3
3. ‚úÖ **Cataloga√ß√£o** dos dados pelo Glue Crawler
4. ‚úÖ **Conex√µes** configuradas entre Glue e Aurora
5. ‚úÖ **Job ETL** pronto para execu√ß√£o visual

## üé® Usando a Ferramenta Visual

### Acessar o AWS Glue Studio:
```bash
# Obter URL do Glue Studio
terraform output glue_studio_url
```

### No Glue Studio voc√™ pode:
- **Visualizar** o fluxo de dados graficamente
- **Modificar** transforma√ß√µes usando interface drag-and-drop
- **Adicionar** novos n√≥s de processamento
- **Testar** diferentes configura√ß√µes
- **Executar** jobs com um clique

### Recursos Pr√©-configurados:
- **Conex√£o Aurora**: `terraform output glue_connection_name`
- **Database Catalog**: `terraform output glue_database_name`
- **Dados S3**: Catalogados e prontos para uso
- **Job ETL**: `terraform output glue_job_name`

## üìä Fluxo de Dados Detalhado

### 1. **Extract (Extra√ß√£o)**
```
Dados Locais ‚Üí S3 ‚Üí Glue Catalog
```
- Arquivos CSV/TSV s√£o enviados para S3
- Glue Crawler descobre esquemas automaticamente
- Metadados ficam dispon√≠veis no Catalog

### 2. **Transform (Transforma√ß√£o)**
```
S3 Data ‚Üí Spark Processing ‚Üí Cleaned Data
```
- **Limpeza**: Remove caracteres especiais, normaliza encoding
- **Convers√£o**: Ajusta tipos de dados (string ‚Üí integer, decimal)
- **Agrega√ß√£o**: Soma reclama√ß√µes por CNPJ/ano
- **Join**: Une dados de diferentes fontes

### 3. **Load (Carregamento)**
```
Processed Data ‚Üí Aurora Serverless ‚Üí Final Tables
```
- Dados limpos s√£o inseridos em tabelas individuais
- Tabela consolidada √© criada com joins entre fontes
- √çndices s√£o criados para performance

## üìã Estrutura das Tabelas

### Tabela `dados_consolidados` (Principal)
```sql
CREATE TABLE dados_consolidados (
    id SERIAL PRIMARY KEY,
    cnpj VARCHAR(20),                    -- CNPJ da institui√ß√£o
    nome_instituicao VARCHAR(200),       -- Nome do banco
    segmento VARCHAR(10),                -- S1, S2, S3, etc.
    ano INTEGER,                         -- Ano de refer√™ncia
    total_reclamacoes INTEGER,           -- Total de reclama√ß√µes
    total_clientes BIGINT,               -- Total de clientes
    indice_reclamacoes DECIMAL(10,2),    -- √çndice m√©dio
    avaliacao_geral DECIMAL(3,1),        -- Nota Glassdoor
    cultura_valores DECIMAL(3,1),        -- Avalia√ß√£o cultura
    remuneracao_beneficios DECIMAL(3,1), -- Avalia√ß√£o sal√°rios
    recomendam_empresa DECIMAL(5,1),     -- % recomenda√ß√£o
    data_processamento TIMESTAMP,
    UNIQUE(cnpj, ano)
);
```

## üîç Verifica√ß√£o e Monitoramento

### Verificar Dados Carregados:
```bash
# Conectar ao Aurora
terraform output -raw data_verification_command

# Contar registros por tabela
SELECT 'reclamacoes' as tabela, count(*) FROM reclamacoes
UNION ALL
SELECT 'bancos_enquadramento', count(*) FROM bancos_enquadramento
UNION ALL
SELECT 'empregados_glassdoor', count(*) FROM empregados_glassdoor
UNION ALL
SELECT 'dados_consolidados', count(*) FROM dados_consolidados;
```

### Monitorar Jobs Glue:
```bash
# Listar execu√ß√µes do job
aws glue get-job-runs --job-name $(terraform output -raw glue_job_name)

# Ver logs no CloudWatch
aws logs describe-log-groups --log-group-name-prefix /aws-glue
```

## üí∞ Custos Estimados

| Servi√ßo | Custo Mensal | Observa√ß√µes |
|---------|--------------|-------------|
| Aurora Serverless v2 | $5-15 | Escala de 0.5-2 ACU conforme uso |
| S3 | $1-3 | Poucos GB de dados |
| Glue | $2-5 | Por execu√ß√£o (~$0.44/hora) |
| VPC/Networking | Gratuito | Dentro dos limites |
| **Total** | **$8-23** | Muito econ√¥mico para desenvolvimento |

## üîß Personaliza√ß√£o

### Modificar Configura√ß√µes:
```hcl
# variables.tf
variable "project_name" {
  default = "meu-projeto-etl"  # Altere aqui
}

variable "aws_region" {
  default = "us-west-2"        # Altere a regi√£o
}
```

### Adicionar Novos Dados:
1. Coloque arquivos na pasta `Dados/`
2. Execute `terraform apply` para upload
3. Execute Glue Crawler para catalogar
4. Modifique job ETL no Glue Studio

## üßπ Limpeza

```bash
# Remover toda a infraestrutura
terraform destroy
```

## üéì Conceitos Aprendidos

- **ETL com Ferramenta Visual**: AWS Glue Studio
- **Banco Serverless v2**: Aurora com auto-scaling cont√≠nuo
- **Infraestrutura como C√≥digo**: Terraform
- **Data Lake**: S3 como reposit√≥rio central
- **Cataloga√ß√£o**: Glue Catalog para metadados
- **Processamento Distribu√≠do**: Spark no Glue
- **Networking AWS**: VPC, subnets, security groups

## üìö Pr√≥ximos Passos

1. **Agendamento**: Configurar execu√ß√£o autom√°tica (CloudWatch Events)
2. **Monitoramento**: Alertas para falhas no ETL
3. **Qualidade**: Valida√ß√£o de dados com Great Expectations
4. **Visualiza√ß√£o**: Conectar com QuickSight ou Grafana
5. **CI/CD**: Pipeline automatizado com GitHub Actions

---

**üéâ Parab√©ns! Voc√™ criou uma solu√ß√£o completa de ETL usando ferramentas visuais na AWS!**
