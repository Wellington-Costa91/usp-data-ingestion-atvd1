# AWS Glue ETL Job: S3 CSV â†’ Aurora PostgreSQL

## ğŸ“Œ DescriÃ§Ã£o
Este script Python implementa um **ETL (Extract, Transform, Load)** utilizando **AWS Glue**, que lÃª arquivos CSV do **Amazon S3**, aplica transformaÃ§Ãµes e grava os dados em uma tabela do **Amazon Aurora PostgreSQL**.  
Ele utiliza conexÃµes do Glue e credenciais armazenadas no **AWS Secrets Manager** para autenticaÃ§Ã£o segura.

---

## ğŸš€ Funcionalidades Principais
- ğŸ”¹ **Leitura de CSV do S3** com detecÃ§Ã£o automÃ¡tica do separador.  
- ğŸ”¹ **TransformaÃ§Ã£o de dados**, incluindo:
  - CriaÃ§Ã£o/normalizaÃ§Ã£o de coluna `id` (primary key).  
  - AdiÃ§Ã£o de colunas `created_at` e `updated_at`.  
  - PadronizaÃ§Ã£o dos nomes das colunas.  
- ğŸ”¹ **CriaÃ§Ã£o automÃ¡tica de schema e tabela** no Aurora PostgreSQL, caso nÃ£o existam.  
- ğŸ”¹ **Escrita dos dados** no banco utilizando JDBC com batch otimizado.  
- ğŸ”¹ **VerificaÃ§Ã£o pÃ³s-inserÃ§Ã£o** para confirmar a carga.  
- ğŸ”¹ **Logging detalhado** em todas as etapas.  

---

## ğŸ“‚ Estrutura do Projeto
```
etl_s3_to_aurora.py   # Script principal do Glue Job
```

---

## âš™ï¸ ParÃ¢metros Esperados

| ParÃ¢metro         | DescriÃ§Ã£o                                           | Exemplo                          |
|-------------------|-----------------------------------------------------|---------------------------------|
| `JOB_NAME`        | Nome do job no AWS Glue                             | `etl_s3_to_aurora`              |
| `S3_INPUT_PATH`   | Caminho do arquivo CSV no S3                        | `s3://bucket/dados/arquivo.csv` |
| `TARGET_TABLE`    | Nome da tabela destino no Aurora PostgreSQL         | `clientes`                      |
| `CONNECTION_NAME` | Nome da conexÃ£o Glue para JDBC (Aurora)             | `aurora-connection`             |
| `SECRET_NAME`     | Nome do secret no AWS Secrets Manager               | `aurora-db-secret`              |
| `DATABASE_NAME`   | Nome do banco de dados no Aurora                    | `mydatabase`                    |
| `SCHEMA_NAME`     | Nome do schema no banco (serÃ¡ criado se nÃ£o existir)| `public`                        |

---

## ğŸ”‘ Formato do Secret no AWS Secrets Manager
```json
{
  "username": "dbuser",
  "password": "dbpassword",
  "host": "aurora-cluster-endpoint",
  "port": 5432
}
```

---

## ğŸ—ï¸ DependÃªncias
- AWS Glue com PySpark (jÃ¡ disponÃ­vel no ambiente Glue)
- `boto3`
- `psycopg2`
- ConexÃ£o JDBC configurada no Glue
- Secret configurado no Secrets Manager

---

## â–¶ï¸ ExecuÃ§Ã£o no AWS Glue
1. FaÃ§a upload do script para o S3.  
2. Crie um Job no Glue apontando para o script.  
3. Configure os parÃ¢metros necessÃ¡rios.  
4. Execute o job e monitore os logs no CloudWatch.  

Exemplo de execuÃ§Ã£o local:
```bash
spark-submit etl_s3_to_aurora.py \
  --JOB_NAME etl_s3_to_aurora \
  --S3_INPUT_PATH s3://bucket/dados/arquivo.csv \
  --TARGET_TABLE clientes \
  --CONNECTION_NAME aurora-connection \
  --SECRET_NAME aurora-db-secret \
  --DATABASE_NAME mydatabase \
  --SCHEMA_NAME public
```

---

## ğŸ“œ Fluxo do Processo
1. ğŸ” **Recupera credenciais** do Aurora via Secrets Manager.  
2. ğŸ“¥ **LÃª arquivo CSV** do S3.  
3. ğŸ”„ **Aplica transformaÃ§Ãµes** e garante consistÃªncia dos dados.  
4. ğŸ—ï¸ **Cria schema/tabela** no Aurora se nÃ£o existirem.  
5. ğŸ“ **Escreve os dados** no banco (modo overwrite ou append).  
6. âœ… **Verifica inserÃ§Ã£o** e registra logs detalhados.  

---

## âœ… Logs
Utiliza o logger nativo do Glue para exibir progresso, contagens, schema e erros detalhados.

---

## ğŸ“Œ ObservaÃ§Ãµes
- A conexÃ£o JDBC do Glue deve possuir acesso Ã  instÃ¢ncia do Aurora.  
- A role do Glue deve ter permissÃµes para acessar S3, Secrets Manager e Aurora.

